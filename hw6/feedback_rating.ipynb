{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Формализация постановки задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "а) Если не будет размечанных данных - то это задача кластеризации. Если в итоге будут размеченные данные, то задача классификации. Удобнее, конечно, с размеченными данными, так как в кластеризации надо будет еще контролировать количество кластеров + понимать, нужные ли кластеры вышли.\n",
    "Регрессию тоже можно пытаться применять (но тут она скорее как бы вместо классификации...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Целевые значения - метки, хороший отзыв или плохой, так же можно использовать большее количество меток (хороший, плохой, нейтральный), или еще больше меток (это уже зависит от того, какие данные у нас появятся, если данные с метками 1-5, то такие метки можно и оставить) (или вероятность \"хорошести\" отзыва [0, 1]).\n",
    "Скорее всего: хороший, плохой, нейтральный (когда мы точно не уверена)\n",
    "\n",
    "Как показываться в демострации?\n",
    "Классы в духе, 0, 1 - не очень, так как неинтуитивно, можно явно текстом прописать. Но для визуализации лучше всего, наверное, выделять цветом. Типа зеленые - хорошие, классые - плохие. (хорошие == позитивные, плохие == негативные)\n",
    "Так же есть способ предоставлять окно для ввода фидбека, которое по нажатию кнопки будет выдавать результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с) Если показывать цифру и говорить accuracy 98%, recall 0.53 - это может быть непонятно тому, кому мы показываем.\n",
    "Можно явно просто словами писать: 98 правильно помеченных отзывов среди 100.\n",
    "Или же визуализировать какими-нибудь диаграммами, например круговая диаграмма должна неплохо подойти (зависит так же от количества классов, если их много, то выйдет перегруженно)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Это стоит спросить у заказчика, наверное.\n",
    "А вообще в идеале - на всех. В идеале должна получиться модель, которая не чувствительна к \"пользовательским ошибкам\", люди, которые пишут отзывы же не знают об этих ограничениях.\n",
    "\n",
    "Возможно, есть смысл накладывать ограничения на язык (напр русский, если банк русский и его аудитория русская), это облегчит обучение модели и не сильно повредит. А опечатки и сленг встречаются, скорее всего, часто. Но это надо наверное напрямую посмотреть на отзывы и понять, есть ли в них эти \"минусы\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Сбор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Со скрапи у меня были проблемы, так что быстрее было по хардкоду."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [2:47:40<00:00,  2.98it/s]  \n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for item in tqdm(range(10100000, 10130000)):\n",
    "    response = requests.get('http://www.banki.ru/services/responses/bank/response/{item}/'.format(item=item))\n",
    "    if response.status_code != 200:\n",
    "        continue\n",
    "    html_doc = response.text\n",
    "    soup = bs4.BeautifulSoup(html_doc, 'html.parser')\n",
    "    feedback_rating_tag = soup.find_all(name=\"meta\", attrs={\"itemprop\": \"value\"})\n",
    "    if len(feedback_rating_tag) != 0:\n",
    "        feedback_rating = feedback_rating_tag[0].get_attribute_list(\"content\")[0]\n",
    "        feedback_text = soup.find_all(name=\"div\", attrs={\"itemprop\": \"description\"})[0].get_text()\n",
    "        X.append(feedback_text)\n",
    "        y.append(int(feedback_rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11565\n",
      "11565\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как в собранных данных рейтинг дается от 1 до 5, то так и оставим.\n",
    "Можно было бы, конечно, и уменьшить колисевтво классов.\n",
    "Так бы мы могли и расширяться на новые данные с других сайтов (не banki.ru)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(X)\n",
    "dataset = count_vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11565, 86297)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве скора просто возьмем accyracy (отношение правильно угаданных ко всем)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y, y_pred):\n",
    "    matched = 0\n",
    "    non_matching_sum = 0\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == y_pred[i]:\n",
    "            matched += 1\n",
    "            non_matching_sum += y[i] - y_pred[i]\n",
    "    return matched / len(y)\n",
    "\n",
    "scorer = make_scorer(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76607884,  0.77250324,  0.76647639])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf, dataset, y, scoring=scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(dataset, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7961954172070903\n"
     ]
    }
   ],
   "source": [
    "print(acc(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохое качество.(в том числе на кросс валидации). Рандом - это точность 0.20. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('model', 'wb') as model_file:\n",
    "    pickle.dump(clf, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer', 'wb') as vectorizer_file:\n",
    "    pickle.dump(count_vectorizer, vectorizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vectorizer', 'rb') as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выполнение и правда понадобилось несколько часов (у меня лично часа 4 заняло). Спасибо!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
